# -*- coding: utf-8 -*-
"""Preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Z9qhp1LnOpOnvICTf-onNmy3mtWxTugF
"""

import numpy as np
import pandas as pd

data=pd.read_csv('data.csv')

data.shape

df.head(5)
df.tail(5)
df.describe()
df.info()
df.groupby('temperature').size()

"""find the unique values"""

df.humidity.unique()
df.humidity.nunique(dropna=True)

unique_values = df.nunique()
print(unique_values)

df.columns

df['label'].unique()

df.dtypes

df['label'].value_counts()

"""extracting independent variables"""

x=df.iloc[:,:-1].values
z=df[["temperature","humidity"]]
y=df.iloc[:,3].values
y=df[["label"]]

"""Write the independent variables"""

x=data[['','','']].values

x

"""write the dependent variable"""

y=data[['']].values

y

"""find the missing values"""

df.isnull().sum()

df.isna().head()
df.isna().sum()

"""deleting the missing values"""

#dropna()
#df_records_dropped = df.dropna(axis=0, how='any',inplace=True)
#df_records_dropped.info()

"""Replacing the missing values"""

#pandas.df.fillna()
#pandas.df.fillna(100)

"""Removing duplicates from the Pandas Data frame"""

#DataFrame.drop_duplicates(subset=None, keep=’first’, inplace=False)

"""To find missing values using mean"""

from sklearn.impute import SimpleImputer

imputer=SimpleImputer(missing_values=np.nan,strategy='mean')

imputer=imputer.fit(x[:,1:3])

x[:,1:3]=imputer.transform(x[:,1:3])

x

"""convert categorial data into numerical data"""

from sklearn.preprocessing import LabelEncoder

label_encode_x=LabelEncoder()

""": indicated rows and 0 indicate the column that has categories"""

x[:0]=label_encode_x.fit_transform(x[:0])

x

"""sometimes after categorising the model might take few things as higher precedence and some as lower so avoid that we will use onehotencoder"""

from sklearn.preprocessing import OneHotEncoder

onehotencoder=OneHotEncoder()

onehotencoder.fit_transform(data.Country.values.reshape(-1,1)).toarray()

"""now complete the same using y"""

label_encode_y=LabelEncoder()

y

"""splitting dataset into train and test"""

from sklearn.model_selection import train_test_split
Xtrain, Xtest, Ytrain, Ytest = train_test_split(x,y,target,test_size = 0.2,random_state =2)

"""feature scaling"""

from sklearn.preprocessing import StandardScaler
st_x= StandardScaler()
Xtrain= st_x.fit_transform(Xtrain)
Xtest= st_x.transform(Xtest)

# Normalization using min max scalar
from sklearn import preprocessing
scaler = preprocessing.MinMaxScaler(feature_range=(0, 2))
norm = scaler.fit_transform(Xtrain)
print(norm)
#Normalization using normalize method
norm_data = preprocessing.normalize(Xtrain, axis=0)
#if the value of axis is 1 it will normalize along rows
#if the value of axis is 0 it will normalize along column
print(norm_data)





