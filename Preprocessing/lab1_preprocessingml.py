# -*- coding: utf-8 -*-
"""Lab1-preprocessingML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xZHbOZbxv7lj_q9AKMGHs6ehNpglbdB8
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import io
df=pd.read_csv('/content/crop_recommendation.csv')

df.shape

df.head(5)

df.tail(5)

df.describe()

df.info()

df.groupby('temperature').size()

"""# Extracting independent variable"""

x=df.iloc[:,:-1].values
z=df[["temperature","humidity"]]
y=df.iloc[:,3].values
y=df[["label"]]

"""# Finding the unique values"""

df.humidity.unique()
df.humidity.nunique(dropna=True)

unique_values = df.nunique()
print(unique_values)

df.columns

df['label'].unique()

df.dtypes

df['label'].value_counts()

"""# Finding the missing values"""

df.isnull().sum()

df.isna().head()
df.isna().sum()

"""# Deleting the missing values"""

#dropna()
#df_records_dropped = df.dropna(axis=0, how='any',inplace=True)
#df_records_dropped.info()

"""# Replacing the missing values"""

#pandas.df.fillna()
#pandas.df.fillna(100)

"""# Removing duplicates from the Pandas Data frame"""

#DataFrame.drop_duplicates(subset=None, keep=’first’, inplace=False)

df.isnull().sum()

features = df[['N', 'P','K','temperature', 'humidity', 'ph', 'rainfall']]
target = df['label']
#features = df[['temperature', 'humidity', 'ph', 'rainfall']]
labels = df['label']

"""# Encoding Categorical data:"""

#from sklearn.preprocessing import LabelEncoder
#label_encoder_x= LabelEncoder()
#x[:, 0]= label_encoder_x.fit_transform(x[:, 0])

"""# Splitting into train and test data"""

# Splitting into train and test data

from sklearn.model_selection import train_test_split
Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size = 0.2,random_state =2)

"""# Feature scaling (Standardization and Normalization)"""

from sklearn.preprocessing import StandardScaler
st_x= StandardScaler()
Xtrain= st_x.fit_transform(Xtrain)
Xtest= st_x.transform(Xtest)

# Normalization using min max scalar
from sklearn import preprocessing
scaler = preprocessing.MinMaxScaler(feature_range=(0, 2))
norm = scaler.fit_transform(Xtrain)
print(norm)
#Normalization using normalize method
norm_data = preprocessing.normalize(Xtrain, axis=0)
#if the value of axis is 1 it will normalize along rows
#if the value of axis is 0 it will normalize along column
print(norm_data)

